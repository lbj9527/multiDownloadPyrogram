"""
ä¸‰å®¢æˆ·ç«¯æ¶ˆæ¯ä¸‹è½½éªŒè¯ç¨‹åº - Stream Media ç‰ˆæœ¬
æ ¸å¿ƒåŠŸèƒ½ï¼šæ™ºèƒ½æ¶ˆæ¯åˆ†é…ã€å¼‚æ­¥ä»»åŠ¡ç®¡ç†ã€TgCryptoåŠ é€Ÿã€æµå¼ä¸‹è½½
ä½¿ç”¨ Pyrogram çš„ stream_media æ–¹æ³•è¿›è¡Œé«˜æ•ˆæµå¼ä¸‹è½½
æ”¯æŒåŸºäºæ–‡ä»¶å¤§å°å’Œç±»å‹çš„æ™ºèƒ½ä¸‹è½½æ–¹æ³•é€‰æ‹©

æ³¨æ„ï¼šæ­¤æ–‡ä»¶ä½¿ç”¨ç¡¬ç¼–ç é…ç½®ï¼Œè¯·åœ¨é…ç½®åŒºåŸŸä¿®æ”¹ç›¸å…³å‚æ•°
"""
import asyncio
import os
import re
import time
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any
from pyrogram.client import Client
from pyrogram.errors import FloodWait
from pyrogram.raw.functions.upload import GetFile
from pyrogram.raw.types import InputDocumentFileLocation, InputPhotoFileLocation
from pyrogram.file_id import FileId, FileType
import logging
import psutil
import threading
import time

# å¯¼å…¥ä¸»ç¨‹åºçš„åˆ†é…ç»„ä»¶
from core.task_distribution import (
    DistributionConfig,
    DistributionMode,
    TaskDistributor
)
from core.task_distribution.base import LoadBalanceMetric

# é…ç½®æ—¥å¿— - å¼ºåˆ¶æ¸…é™¤å¹¶é‡æ–°é…ç½®
def setup_logging(verbose: bool = True):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # ç¡®ä¿logsç›®å½•å­˜åœ¨
    logs_dir = Path("logs")
    logs_dir.mkdir(exist_ok=True)
    log_file = logs_dir / "test_downloader_stream.log"

    # å¼ºåˆ¶æ¸…é™¤ä¹‹å‰çš„æ—¥å¿—æ–‡ä»¶
    if log_file.exists():
        log_file.unlink()

    # æ¸…é™¤æ‰€æœ‰ç°æœ‰çš„æ—¥å¿—å¤„ç†å™¨
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # æ¸…é™¤æ‰€æœ‰å­loggerçš„å¤„ç†å™¨
    for name in logging.Logger.manager.loggerDict:
        logger_obj = logging.getLogger(name)
        logger_obj.handlers.clear()
        logger_obj.propagate = True

    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # é…ç½®æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)

    # é…ç½®æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)

    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)

    # é…ç½®Pyrogramæ—¥å¿—çº§åˆ«
    if verbose:
        logging.getLogger("pyrogram").setLevel(logging.INFO)
    else:
        # è®¾ç½®æ›´ä¸¥æ ¼çš„æ—¥å¿—çº§åˆ«ï¼Œå‡å°‘ç½‘ç»œè¿æ¥æ—¥å¿—
        logging.getLogger("pyrogram").setLevel(logging.ERROR)
        logging.getLogger("pyrogram.connection").setLevel(logging.ERROR)
        logging.getLogger("pyrogram.session").setLevel(logging.ERROR)
        logging.getLogger("pyrogram.dispatcher").setLevel(logging.WARNING)
        logging.getLogger("pyrogram.connection.transport").setLevel(logging.ERROR)
        logging.getLogger("pyrogram.connection.transport.tcp").setLevel(logging.ERROR)

setup_logging(verbose=False)  # ç¦ç”¨Pyrogramè¯¦ç»†æ—¥å¿—
logger = logging.getLogger(__name__)

# ==================== é…ç½®åŒºåŸŸ ====================
API_ID = 25098445
API_HASH = "cc2fa5a762621d306d8de030614e4555"
PHONE_NUMBER = "+8618758361347"
TARGET_CHANNEL = "csdkl"
START_MESSAGE_ID = 72710
END_MESSAGE_ID = 72849
TOTAL_MESSAGES = END_MESSAGE_ID - START_MESSAGE_ID + 1
SESSION_NAMES = [
    "client_8618758361347_1",
    "client_8618758361347_2",
    "client_8618758361347_3",
]
USE_PROXY = True
PROXY_CONFIG = {
    "scheme": "socks5",
    "hostname": "127.0.0.1",
    "port": 7890
} if USE_PROXY else None
DOWNLOAD_DIR = Path("downloads")

# è°ƒè¯•é€‰é¡¹ - å·²ç§»é™¤æ— ç”¨çš„é…ç½®é¡¹
# ==================== é…ç½®åŒºåŸŸç»“æŸ ====================

def monitor_bandwidth():
    """ç›‘æ§ç½‘ç»œå¸¦å®½ä½¿ç”¨æƒ…å†µ"""
    old_stats = psutil.net_io_counters()
    while True:
        time.sleep(1)
        new_stats = psutil.net_io_counters()
        download_speed = (new_stats.bytes_recv - old_stats.bytes_recv) / 1024
        upload_speed = (new_stats.bytes_sent - old_stats.bytes_sent) / 1024
        logger.info(f"Download: {download_speed:.2f} KB/s, Upload: {upload_speed:.2f} KB/s")
        old_stats = new_stats

class MultiClientDownloader:
    """å¤šå®¢æˆ·ç«¯ä¸‹è½½ç®¡ç†å™¨ - Stream Media ç‰ˆæœ¬ + æ™ºèƒ½æ¶ˆæ¯åˆ†é…"""
    def __init__(self):
        self.clients: List[Client] = []
        self.download_dir = DOWNLOAD_DIR
        self.download_dir.mkdir(exist_ok=True)
        self.channel_info = None
        self.channel_dir = None
        self.stats = {
            "total_messages": TOTAL_MESSAGES,
            "downloaded": 0,
            "failed": 0,
            "start_time": None
        }
        self._results_processed = False  # é˜²æ­¢é‡å¤è¾“å‡ºç»Ÿè®¡ä¿¡æ¯

        # åˆå§‹åŒ–æ™ºèƒ½æ¶ˆæ¯åˆ†é…å™¨ï¼ˆç®€åŒ–é…ç½®ï¼‰
        self.distribution_config = DistributionConfig(
            mode=DistributionMode.MEDIA_GROUP_AWARE,  # ä½¿ç”¨åª’ä½“ç»„æ„ŸçŸ¥åˆ†é…
            load_balance_metric=LoadBalanceMetric.ESTIMATED_SIZE,  # ä½¿ç”¨çœŸå®æ–‡ä»¶å¤§å°è¿›è¡Œè´Ÿè½½å‡è¡¡
            prefer_large_groups_first=True,  # ä¼˜å…ˆåˆ†é…å¤§åª’ä½“ç»„
            enable_validation=True  # å¯ç”¨åŸºæœ¬éªŒè¯
        )

    def create_clients(self) -> List[Client]:
        """åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹"""
        clients = []
        for session_name in SESSION_NAMES:
            client = Client(
                name=session_name,
                api_id=API_ID,
                api_hash=API_HASH,
                workdir="sessions",
                proxy=PROXY_CONFIG,
                workers=4,
                sleep_threshold=10
            )
            clients.append(client)
            logger.info(f"åˆ›å»ºå®¢æˆ·ç«¯: {session_name}")
        self.clients = clients
        return clients

    async def get_channel_info(self, client: Client) -> Dict:
        """è·å–é¢‘é“ä¿¡æ¯"""
        try:
            chat = await client.get_chat(TARGET_CHANNEL)
            username = f"@{chat.username}" if chat.username else f"id_{chat.id}"
            title = chat.title or "Unknown"
            safe_title = self.sanitize_filename(title)
            folder_name = f"{username}-{safe_title}"
            return {
                "username": username,
                "title": title,
                "folder_name": folder_name,
                "chat_id": chat.id
            }
        except Exception as e:
            logger.error(f"è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "username": f"@{TARGET_CHANNEL}",
                "title": "Unknown",
                "folder_name": f"@{TARGET_CHANNEL}-Unknown",
                "chat_id": None
            }

    def sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
        illegal_chars = r'[<>:"/\\|?*]'
        safe_name = re.sub(illegal_chars, '_', filename)
        safe_name = safe_name.strip('. ')
        return safe_name[:100]

    def get_channel_directory(self) -> Path:
        """è·å–é¢‘é“ä¸“ç”¨ç›®å½•ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼‰"""
        if not self.channel_info:
            raise ValueError("é¢‘é“ä¿¡æ¯æœªåˆå§‹åŒ–")
        if self.channel_dir is not None:
            return self.channel_dir
        self.channel_dir = self.download_dir / self.channel_info["folder_name"]
        if self.channel_dir.exists():
            logger.info(f"é¢‘é“ç›®å½•å·²å­˜åœ¨: {self.channel_dir}")
        else:
            self.channel_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"é¢‘é“ç›®å½•å·²åˆ›å»º: {self.channel_dir}")
        return self.channel_dir

    def is_media_group_message(self, message) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å±äºåª’ä½“ç»„"""
        return hasattr(message, 'media_group_id') and message.media_group_id is not None

    def generate_filename_by_type(self, message) -> str:
        """æ ¹æ®æ¶ˆæ¯ç±»å‹ç”Ÿæˆæ–‡ä»¶å"""
        if self.is_media_group_message(message):
            base_name = f"{message.media_group_id}-{message.id}"
        else:
            base_name = f"msg-{message.id}"
        extension = self.get_file_extension(message)
        return f"{base_name}{extension}"

    def get_file_extension(self, message) -> str:
        """è·å–æ¶ˆæ¯åª’ä½“çš„æ–‡ä»¶æ‰©å±•å"""
        if hasattr(message, 'document') and message.document:
            if hasattr(message.document, 'file_name') and message.document.file_name:
                _, ext = os.path.splitext(message.document.file_name)
                return ext if ext else self.get_extension_from_mime(message.document.mime_type)
            else:
                return self.get_extension_from_mime(getattr(message.document, 'mime_type', ''))
        elif hasattr(message, 'video') and message.video:
            return '.mp4'
        elif hasattr(message, 'photo') and message.photo:
            return '.jpg'
        elif hasattr(message, 'audio') and message.audio:
            if hasattr(message.audio, 'file_name') and message.audio.file_name:
                _, ext = os.path.splitext(message.audio.file_name)
                return ext if ext else '.mp3'
            return '.mp3'
        elif hasattr(message, 'voice') and message.voice:
            return '.ogg'
        elif hasattr(message, 'video_note') and message.video_note:
            return '.mp4'
        elif hasattr(message, 'animation') and message.animation:
            if hasattr(message.animation, 'file_name') and message.animation.file_name:
                _, ext = os.path.splitext(message.animation.file_name)
                return ext if ext else '.gif'
            return '.gif'
        elif hasattr(message, 'sticker') and message.sticker:
            return '.webp'
        else:
            return '.bin'

    def get_extension_from_mime(self, mime_type: str) -> str:
        """æ ¹æ®MIMEç±»å‹è·å–æ–‡ä»¶æ‰©å±•å"""
        mime_to_ext = {
            'video/mp4': '.mp4',
            'video/avi': '.avi',
            'video/mkv': '.mkv',
            'video/mov': '.mov',
            'video/webm': '.webm',
            'image/jpeg': '.jpg',
            'image/png': '.png',
            'image/gif': '.gif',
            'image/webp': '.webp',
            'audio/mpeg': '.mp3',
            'audio/wav': '.wav',
            'audio/ogg': '.ogg',
            'audio/m4a': '.m4a',
            'application/pdf': '.pdf',
            'application/zip': '.zip',
            'application/x-rar': '.rar',
            'text/plain': '.txt',
            'application/msword': '.doc',
            'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
        }
        return mime_to_ext.get(mime_type, '.bin')

    async def save_text_message(self, message):
        """ä¿å­˜æ–‡æœ¬æ¶ˆæ¯åˆ°é¢‘é“ç›®å½•"""
        try:
            channel_dir = self.get_channel_directory()
            text_file = channel_dir / "messages.txt"
            with open(text_file, "a", encoding="utf-8") as f:
                if self.is_media_group_message(message):
                    f.write(f"æ¶ˆæ¯ID: {message.id} (åª’ä½“ç»„: {message.media_group_id})\n")
                else:
                    f.write(f"æ¶ˆæ¯ID: {message.id}\n")
                f.write(f"æ—¶é—´: {message.date}\n")
                f.write(f"å†…å®¹: {message.text or 'æ— æ–‡æœ¬å†…å®¹'}\n")
                f.write("-" * 50 + "\n")
        except Exception as e:
            logger.error(f"ä¿å­˜æ–‡æœ¬æ¶ˆæ¯å¤±è´¥: {e}")



    async def parallel_fetch_messages(self, clients: List[Client]) -> List[Any]:
        """
        å¹¶å‘è·å–æ¶ˆæ¯ - å¤šå®¢æˆ·ç«¯åˆ†å·¥è·å–ä¸åŒèŒƒå›´çš„æ¶ˆæ¯

        Args:
            clients: å®¢æˆ·ç«¯åˆ—è¡¨

        Returns:
            æ‰€æœ‰è·å–åˆ°çš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.info(f"ğŸš€ ä½¿ç”¨ {len(clients)} ä¸ªå®¢æˆ·ç«¯å¹¶å‘è·å–æ¶ˆæ¯...")

        # å°†æ¶ˆæ¯èŒƒå›´æŒ‰å®¢æˆ·ç«¯æ•°é‡åˆ†é…
        all_message_ids = list(range(START_MESSAGE_ID, END_MESSAGE_ID + 1))
        client_count = len(clients)

        # è®¡ç®—æ¯ä¸ªå®¢æˆ·ç«¯çš„æ¶ˆæ¯èŒƒå›´
        messages_per_client = len(all_message_ids) // client_count
        remainder = len(all_message_ids) % client_count

        ranges = []
        start_idx = 0
        for i in range(client_count):
            extra = 1 if i < remainder else 0
            end_idx = start_idx + messages_per_client + extra
            ranges.append(all_message_ids[start_idx:end_idx])
            logger.info(f"å®¢æˆ·ç«¯{i+1} åˆ†é…æ¶ˆæ¯èŒƒå›´: {all_message_ids[start_idx]} - {all_message_ids[end_idx-1]} ({len(ranges[i])} æ¡)")
            start_idx = end_idx

        async def fetch_range(client, message_ids, client_index):
            """å•ä¸ªå®¢æˆ·ç«¯è·å–æŒ‡å®šèŒƒå›´çš„æ¶ˆæ¯"""
            # é”™å¼€å¯åŠ¨æ—¶é—´é¿å…åŒæ—¶å‘èµ·è¯·æ±‚
            if client_index > 0:
                delay = client_index * 0.2
                logger.info(f"å®¢æˆ·ç«¯{client_index+1} å°†åœ¨ {delay} ç§’åå¼€å§‹è·å–...")
                await asyncio.sleep(delay)

            messages = []
            batch_size = 100  # æ¯æ‰¹è·å–100æ¡æ¶ˆæ¯

            logger.info(f"å®¢æˆ·ç«¯{client_index+1} å¼€å§‹è·å– {len(message_ids)} æ¡æ¶ˆæ¯...")

            for i in range(0, len(message_ids), batch_size):
                batch_ids = message_ids[i:i + batch_size]
                try:
                    batch_messages = await client.get_messages(TARGET_CHANNEL, batch_ids)
                    # è¿‡æ»¤æ‰æ— æ•ˆæ¶ˆæ¯ï¼ˆä½¿ç”¨emptyå±æ€§åˆ¤æ–­ï¼‰
                    valid_messages = [msg for msg in batch_messages if msg is not None and not getattr(msg, 'empty', True)]
                    invalid_count = len(batch_ids) - len(valid_messages)

                    messages.extend(valid_messages)

                    if invalid_count > 0:
                        logger.warning(f"å®¢æˆ·ç«¯{client_index+1} æ‰¹æ¬¡ä¸­å‘ç° {invalid_count} æ¡æ— æ•ˆæ¶ˆæ¯")

                    logger.info(f"å®¢æˆ·ç«¯{client_index+1} å·²è·å– {len(messages)} æ¡æœ‰æ•ˆæ¶ˆæ¯ï¼ˆæ‰¹æ¬¡: {len(valid_messages)}/{len(batch_ids)}ï¼‰")

                    # çŸ­æš‚å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                    await asyncio.sleep(0.1)

                except FloodWait as e:
                    logger.warning(f"å®¢æˆ·ç«¯{client_index+1} é‡åˆ°é™æµï¼Œç­‰å¾… {e.value} ç§’")
                    await asyncio.sleep(float(e.value))
                    # é‡è¯•å½“å‰æ‰¹æ¬¡
                    try:
                        batch_messages = await client.get_messages(TARGET_CHANNEL, batch_ids)
                        # è¿‡æ»¤æ‰æ— æ•ˆæ¶ˆæ¯ï¼ˆä½¿ç”¨emptyå±æ€§åˆ¤æ–­ï¼‰
                        valid_messages = [msg for msg in batch_messages if msg is not None and not getattr(msg, 'empty', True)]
                        invalid_count = len(batch_ids) - len(valid_messages)

                        messages.extend(valid_messages)

                        if invalid_count > 0:
                            logger.warning(f"å®¢æˆ·ç«¯{client_index+1} é‡è¯•æ‰¹æ¬¡ä¸­å‘ç° {invalid_count} æ¡æ— æ•ˆæ¶ˆæ¯")

                        logger.info(f"å®¢æˆ·ç«¯{client_index+1} é‡è¯•æˆåŠŸï¼Œå·²è·å– {len(messages)} æ¡æœ‰æ•ˆæ¶ˆæ¯")
                    except Exception as retry_e:
                        logger.error(f"å®¢æˆ·ç«¯{client_index+1} é‡è¯•å¤±è´¥: {retry_e}")

                except Exception as e:
                    logger.error(f"å®¢æˆ·ç«¯{client_index+1} è·å–æ¶ˆæ¯æ‰¹æ¬¡ {batch_ids[0]}-{batch_ids[-1]} å¤±è´¥: {e}")
                    continue

            logger.info(f"âœ… å®¢æˆ·ç«¯{client_index+1} å®Œæˆè·å–ï¼Œå…± {len(messages)} æ¡æœ‰æ•ˆæ¶ˆæ¯")
            return messages

        # å¯åŠ¨æ‰€æœ‰å®¢æˆ·ç«¯å¹¶å‘è·å–
        tasks = []
        for i, client in enumerate(clients):
            task = fetch_range(client, ranges[i], i)
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        logger.info("â³ ç­‰å¾…æ‰€æœ‰å®¢æˆ·ç«¯å®Œæˆæ¶ˆæ¯è·å–...")
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # åˆå¹¶æ‰€æœ‰æ¶ˆæ¯
        all_messages = []
        successful_clients = 0

        for i, result in enumerate(results):
            if isinstance(result, list):
                all_messages.extend(result)
                successful_clients += 1
                logger.info(f"âœ… å®¢æˆ·ç«¯{i+1} æˆåŠŸè·å– {len(result)} æ¡æ¶ˆæ¯")
            else:
                logger.error(f"âŒ å®¢æˆ·ç«¯{i+1} è·å–æ¶ˆæ¯å¤±è´¥: {result}")

        # æŒ‰æ¶ˆæ¯IDæ’åºç¡®ä¿é¡ºåºæ­£ç¡®ï¼ŒåŒæ—¶è¿‡æ»¤æ‰æ— æ•ˆæ¶ˆæ¯
        all_messages = sorted([msg for msg in all_messages if msg and not getattr(msg, 'empty', True)], key=lambda x: x.id)

        logger.info(f"ğŸ‰ å¹¶å‘è·å–å®Œæˆï¼{successful_clients}/{len(clients)} ä¸ªå®¢æˆ·ç«¯æˆåŠŸï¼Œå…±è·å– {len(all_messages)} æ¡æœ‰æ•ˆæ¶ˆæ¯")
        return all_messages

    async def smart_distribute_messages(self, clients: List[Client]) -> Tuple[Dict[str, List[int]], Dict[str, List[Any]], Dict[str, Any]]:
        """
        æ™ºèƒ½æ¶ˆæ¯åˆ†é… - å¹¶å‘è·å– + åª’ä½“ç»„æ„ŸçŸ¥ç®—æ³• + æ¶ˆæ¯éªŒè¯

        Args:
            clients: å®¢æˆ·ç«¯åˆ—è¡¨ï¼ˆç”¨äºå¹¶å‘è·å–ï¼‰

        Returns:
            Tuple[Dict[client_name, List[message_ids]], Dict[client_name, List[message_objects]], validation_stats] - åˆ†é…ç»“æœã€æ¶ˆæ¯å¯¹è±¡å’ŒéªŒè¯ç»Ÿè®¡
        """
        logger.info("ğŸ§  å¼€å§‹æ™ºèƒ½æ¶ˆæ¯åˆ†é…ï¼ˆå¹¶å‘è·å– + æ™ºèƒ½åˆ†é…ï¼‰...")

        try:
            # 1. å¹¶å‘è·å–æ‰€æœ‰æ¶ˆæ¯å¯¹è±¡
            logger.info(f"ğŸ“¦ ä½¿ç”¨ {len(clients)} ä¸ªå®¢æˆ·ç«¯å¹¶å‘è·å–æ¶ˆæ¯èŒƒå›´ {START_MESSAGE_ID}-{END_MESSAGE_ID}...")
            all_messages = await self.parallel_fetch_messages(clients)

            if not all_messages:
                raise ValueError("æœªèƒ½è·å–åˆ°ä»»ä½•æœ‰æ•ˆæ¶ˆæ¯")

            # 2. ä½¿ç”¨ä¸»ç¨‹åºçš„åˆ†ç»„æ–¹æ³•ï¼ˆé¿å…æ¶ˆæ¯è½¬æ¢è¿‡ç¨‹ä¸­çš„ä¿¡æ¯ä¸¢å¤±ï¼‰
            logger.info("ğŸ§  ä½¿ç”¨ä¸»ç¨‹åºçš„MessageGrouperè¿›è¡Œåˆ†ç»„...")
            from core.message_grouper import MessageGrouper

            # åˆ›å»ºæ¶ˆæ¯åˆ†ç»„å™¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            message_grouper = MessageGrouper()

            # ç›´æ¥ä»æ¶ˆæ¯åˆ—è¡¨è¿›è¡Œåˆ†ç»„ï¼ˆé¿å…è½¬æ¢è¿‡ç¨‹ä¸­çš„ä¿¡æ¯ä¸¢å¤±ï¼‰
            message_collection = message_grouper.group_messages_from_list(all_messages)

            # è®°å½•åˆ†ç»„ç»Ÿè®¡
            grouping_stats = message_collection.get_statistics()
            logger.info(f"ğŸ“Š åˆ†ç»„å®Œæˆ: {grouping_stats['media_groups_count']} ä¸ªåª’ä½“ç»„, {grouping_stats['single_messages_count']} ä¸ªå•æ¶ˆæ¯")

            # 3. ä½¿ç”¨ä¸»ç¨‹åºçš„TaskDistributorè¿›è¡Œåˆ†é…
            logger.info("âš–ï¸ ä½¿ç”¨ä¸»ç¨‹åºçš„TaskDistributorè¿›è¡Œåˆ†é…...")

            # ä½¿ç”¨ç±»çš„é…ç½®ï¼ˆé¿å…é‡å¤é…ç½®ï¼‰
            distribution_config = self.distribution_config

            # æ‰§è¡Œä»»åŠ¡åˆ†é…
            task_distributor = TaskDistributor(distribution_config)
            distribution_result = await task_distributor.distribute_tasks(
                message_collection, SESSION_NAMES
            )

            # 4. è½¬æ¢ä¸ºå®¢æˆ·ç«¯æ¶ˆæ¯IDæ˜ å°„å’Œæ¶ˆæ¯å¯¹è±¡æ˜ å°„
            client_message_mapping = {}
            client_message_objects = {}

            # ä¸å†éœ€è¦æ¶ˆæ¯IDæ˜ å°„ï¼Œç›´æ¥ä½¿ç”¨ä¸»ç¨‹åºçš„æ–¹æ³•

            for assignment in distribution_result.client_assignments:
                client_name = assignment.client_name
                # ç›´æ¥è·å–æ‰€æœ‰æ¶ˆæ¯å¯¹è±¡ï¼ˆä¸»ç¨‹åºæ–¹æ³•ï¼‰
                message_objects = assignment.get_all_messages()
                message_ids = [msg.id for msg in message_objects if msg]

                client_message_mapping[client_name] = message_ids
                client_message_objects[client_name] = message_objects

            # 5. è®°å½•åˆ†é…ç»Ÿè®¡ï¼ˆä½¿ç”¨ä¸»ç¨‹åºçš„ç»Ÿè®¡æ–¹æ³•ï¼‰
            load_balance_stats = distribution_result.get_load_balance_stats()
            logger.info("ğŸ“Š ä»»åŠ¡åˆ†é…ç»Ÿè®¡:")
            logger.info(f"  æ€»æ¶ˆæ¯æ•°: {distribution_result.total_messages}")
            logger.info(f"  æ€»æ–‡ä»¶æ•°: {distribution_result.total_files}")
            logger.info(f"  å®¢æˆ·ç«¯æ•°é‡: {load_balance_stats['clients_count']}")

            # æ‰“å°æ¯ä¸ªå®¢æˆ·ç«¯åˆ†é…åˆ°çš„å®Œæ•´æ¶ˆæ¯ID
            for i, client_name in enumerate(SESSION_NAMES):
                if client_name in client_message_mapping:
                    message_ids = client_message_mapping[client_name]
                    if message_ids:
                        # æ’åºæ¶ˆæ¯IDä»¥ä¾¿æŸ¥çœ‹
                        sorted_ids = sorted(message_ids)
                        id_ranges = []

                        # å°†è¿ç»­çš„IDåˆå¹¶ä¸ºèŒƒå›´æ˜¾ç¤º
                        start = sorted_ids[0]
                        end = sorted_ids[0]

                        for msg_id in sorted_ids[1:]:
                            if msg_id == end + 1:
                                end = msg_id
                            else:
                                if start == end:
                                    id_ranges.append(str(start))
                                else:
                                    id_ranges.append(f"{start}-{end}")
                                start = end = msg_id

                        # æ·»åŠ æœ€åä¸€ä¸ªèŒƒå›´
                        if start == end:
                            id_ranges.append(str(start))
                        else:
                            id_ranges.append(f"{start}-{end}")

                        logger.info(f"  å®¢æˆ·ç«¯{i+1} åˆ†é…æ¶ˆæ¯ID: {', '.join(id_ranges)} (å…±{len(message_ids)}æ¡)")
                    else:
                        logger.info(f"  å®¢æˆ·ç«¯{i+1} åˆ†é…æ¶ˆæ¯ID: æ—  (å…±0æ¡)")

            logger.info(f"  æ–‡ä»¶åˆ†å¸ƒ: {load_balance_stats['file_distribution']}")
            logger.info(f"  å¤§å°åˆ†å¸ƒ: {[f'{size/(1024*1024):.2f} MB' for size in load_balance_stats['size_distribution']]}")
            logger.info(f"  æ–‡ä»¶å‡è¡¡æ¯”ä¾‹: {load_balance_stats['file_balance_ratio']:.3f}")
            logger.info(f"  å¤§å°å‡è¡¡æ¯”ä¾‹: {load_balance_stats['size_balance_ratio']:.3f}")

            logger.info("âœ… æ™ºèƒ½æ¶ˆæ¯åˆ†é…å®Œæˆ")

            # åˆ›å»ºå…¼å®¹çš„ç»Ÿè®¡ä¿¡æ¯
            validation_stats = {
                "enabled": True,
                "original_count": len(all_messages),
                "valid_count": distribution_result.total_messages,
                "invalid_count": len(all_messages) - distribution_result.total_messages,
                "validation_rate": distribution_result.total_messages / len(all_messages) if all_messages else 0,
                "invalid_ids": []
            }

            return client_message_mapping, client_message_objects, validation_stats

        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æ¶ˆæ¯åˆ†é…å¤±è´¥: {e}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä¸å†å›é€€
            raise

    def is_video_file(self, message) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶"""
        if hasattr(message, 'video') and message.video:
            return True
        elif hasattr(message, 'video_note') and message.video_note:
            return True
        elif hasattr(message, 'animation') and message.animation:
            return True
        elif hasattr(message, 'document') and message.document:
            mime_type = getattr(message.document, 'mime_type', '')
            if mime_type.startswith('video/'):
                return True
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_name = getattr(message.document, 'file_name', '')
            if file_name:
                video_extensions = ['.mp4', '.avi', '.mkv', '.mov', '.webm', '.flv', '.wmv', '.m4v']
                _, ext = os.path.splitext(file_name.lower())
                return ext in video_extensions
        return False

    def get_file_size_bytes(self, message) -> int:
        """è·å–æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰- æ”¯æŒæ‰€æœ‰åª’ä½“ç±»å‹"""
        # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„åª’ä½“ç±»å‹
        media_types = ['document', 'video', 'photo', 'audio', 'voice',
                      'video_note', 'animation', 'sticker']

        for media_type in media_types:
            media = getattr(message, media_type, None)
            if media and hasattr(media, 'file_size') and media.file_size:
                return media.file_size

        return 0

    def get_file_size_mb(self, message) -> float:
        """è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰- æ”¯æŒæ‰€æœ‰åª’ä½“ç±»å‹"""
        return self.get_file_size_bytes(message) / 1024 / 1024

    async def download_media_file_raw_api(self, client: Client, message) -> Optional[Path]:
        """ä½¿ç”¨RAW APIæ–¹æ³•ä¸‹è½½åª’ä½“æ–‡ä»¶ï¼ˆæ¥è‡ªtest_downloader.pyï¼‰"""
        try:
            channel_dir = self.get_channel_directory()
            file_name = self.generate_filename_by_type(message)
            file_path = channel_dir / file_name
            file_size = self.get_file_size_bytes(message)
            logger.info(f"RAW APIä¸‹è½½æ¶ˆæ¯ {message.id} (å¤§å°: {file_size / 1024 / 1024:.2f} MB)")

            # è·å–åª’ä½“å¯¹è±¡
            media = (message.document or message.video or message.photo or message.audio or
                     message.voice or message.video_note or message.animation or message.sticker)
            if not media:
                logger.error(f"æ¶ˆæ¯ {message.id} æ— æœ‰æ•ˆåª’ä½“")
                return None

            # è§£ç  file_id è·å–æ–‡ä»¶ä½ç½®
            file_id_str = media.file_id
            file_id_obj = FileId.decode(file_id_str)
            logger.info(f"æ¶ˆæ¯ {message.id} åª’ä½“ç±»å‹: {FileType(file_id_obj.file_type).name}")

            # æ„é€ æ–‡ä»¶ä½ç½®
            if file_id_obj.file_type == FileType.PHOTO:
                location = InputPhotoFileLocation(
                    id=file_id_obj.media_id,
                    access_hash=file_id_obj.access_hash,
                    file_reference=file_id_obj.file_reference,
                    thumb_size=file_id_obj.thumbnail_size or ''
                )
            else:
                location = InputDocumentFileLocation(
                    id=file_id_obj.media_id,
                    access_hash=file_id_obj.access_hash,
                    file_reference=file_id_obj.file_reference,
                    thumb_size=file_id_obj.thumbnail_size or ''
                )

            # å¤„ç†æ•°æ®ä¸­å¿ƒè¿ç§»å’Œåˆ†ç‰‡ä¸‹è½½
            offset = 0
            chunk_size = 1024 * 1024  # 1MBï¼ŒTelegram API æœ€å¤§å€¼

            # æ£€æŸ¥æ–‡ä»¶çš„æ•°æ®ä¸­å¿ƒID
            dc_id = file_id_obj.dc_id
            current_dc_id = await client.storage.dc_id()

            # å¦‚æœæ–‡ä»¶åœ¨ä¸åŒçš„æ•°æ®ä¸­å¿ƒï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if dc_id != current_dc_id:
                logger.info(f"æ¶ˆæ¯ {message.id} æ–‡ä»¶ä½äºæ•°æ®ä¸­å¿ƒ {dc_id}ï¼Œå½“å‰è¿æ¥åˆ° {current_dc_id}")
                # ä½¿ç”¨ Pyrogram çš„å†…ç½®ä¸‹è½½æ–¹æ³•å¤„ç†æ•°æ®ä¸­å¿ƒè¿ç§»
                try:
                    downloaded_path = await client.download_media(message, file_name=str(file_path))
                    if downloaded_path:
                        logger.info(f"âœ… ä½¿ç”¨å†…ç½®æ–¹æ³•ä¸‹è½½å®Œæˆ: {downloaded_path}")
                        return Path(downloaded_path)
                    else:
                        logger.error(f"âŒ å†…ç½®æ–¹æ³•ä¸‹è½½å¤±è´¥")
                        return None
                except Exception as e:
                    logger.error(f"âŒ å†…ç½®æ–¹æ³•ä¸‹è½½å¼‚å¸¸: {e}")
                    return None

            # å¦‚æœåœ¨åŒä¸€æ•°æ®ä¸­å¿ƒï¼Œä½¿ç”¨ RAW API ä¸‹è½½
            try:
                with open(file_path, 'wb') as f:
                    while offset < file_size or file_size == 0:
                        try:
                            result = await client.invoke(GetFile(
                                location=location,
                                offset=offset,
                                limit=chunk_size
                            ))
                            if not hasattr(result, 'bytes') or not result.bytes:
                                break
                            f.write(result.bytes)
                            offset += len(result.bytes)
                        except FloodWait as e:
                            logger.warning(f"RAW APIä¸‹è½½æ¶ˆæ¯ {message.id} é‡åˆ°é™æµï¼Œç­‰å¾… {e.value} ç§’")
                            await asyncio.sleep(float(e.value))
                            continue
                        except Exception as e:
                            logger.error(f"RAW APIä¸‹è½½æ¶ˆæ¯ {message.id} åˆ†ç‰‡å¤±è´¥: {e}")
                            return None
                return Path(file_path) if file_path.exists() else None
            except FloodWait as e:
                logger.warning(f"RAW APIä¸‹è½½æ¶ˆæ¯ {message.id} é‡åˆ°é™æµï¼Œç­‰å¾… {e.value} ç§’")
                await asyncio.sleep(float(e.value))
                return await self.download_media_file_raw_api(client, message)
            except Exception as e:
                logger.error(f"RAW APIä¸‹è½½æ¶ˆæ¯ {message.id} å¤±è´¥: {e}")
                return None
        except Exception as e:
            logger.error(f"RAW APIä¸‹è½½æ¶ˆæ¯ {message.id} å¤±è´¥: {e}")
            return None

    async def download_media_file_stream(self, client: Client, message) -> Optional[Path]:
        """ä½¿ç”¨ stream_media æ–¹æ³•ä¸‹è½½åª’ä½“æ–‡ä»¶"""
        try:
            channel_dir = self.get_channel_directory()
            file_name = self.generate_filename_by_type(message)
            file_path = channel_dir / file_name

            # è·å–æ–‡ä»¶å¤§å°ä¿¡æ¯
            file_size = self.get_file_size_bytes(message)

            logger.info(f"Streamä¸‹è½½æ¶ˆæ¯ {message.id} (å¤§å°: {file_size / 1024 / 1024:.2f} MB)")

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆåª’ä½“
            media = (message.document or message.video or message.photo or message.audio or
                     message.voice or message.video_note or message.animation or message.sticker)
            if not media:
                logger.error(f"æ¶ˆæ¯ {message.id} æ— æœ‰æ•ˆåª’ä½“")
                return None

            # ä½¿ç”¨ stream_media è¿›è¡Œæµå¼ä¸‹è½½
            try:
                downloaded_bytes = 0
                with open(file_path, 'wb') as f:
                    async for chunk in client.stream_media(message):
                        f.write(chunk)
                        downloaded_bytes += len(chunk)

                        # å¯é€‰ï¼šæ˜¾ç¤ºä¸‹è½½è¿›åº¦ï¼ˆæ¯10MBæ˜¾ç¤ºä¸€æ¬¡ï¼‰
                        if downloaded_bytes % (10 * 1024 * 1024) == 0:
                            progress_mb = downloaded_bytes / 1024 / 1024
                            logger.info(f"æ¶ˆæ¯ {message.id} å·²ä¸‹è½½: {progress_mb:.1f} MB")

                # éªŒè¯ä¸‹è½½å®Œæ•´æ€§
                actual_size = file_path.stat().st_size
                if file_size > 0 and actual_size != file_size:
                    logger.warning(f"æ¶ˆæ¯ {message.id} æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {file_size}, å®é™… {actual_size}")

                logger.info(f"Streamä¸‹è½½å®Œæˆ: {file_path.name} ({actual_size / 1024 / 1024:.2f} MB)")
                return file_path

            except FloodWait as e:
                logger.warning(f"Streamä¸‹è½½æ¶ˆæ¯ {message.id} é‡åˆ°é™æµï¼Œç­‰å¾… {e.value} ç§’")
                await asyncio.sleep(float(e.value))
                # é€’å½’é‡è¯•
                return await self.download_media_file_stream(client, message)

            except Exception as e:
                logger.error(f"Streamä¸‹è½½æ¶ˆæ¯ {message.id} å¤±è´¥: {e}")
                # æ¸…ç†ä¸å®Œæ•´çš„æ–‡ä»¶
                if file_path.exists():
                    file_path.unlink()
                return None

        except Exception as e:
            logger.error(f"Streamä¸‹è½½æ¶ˆæ¯ {message.id} å¤±è´¥: {e}")
            return None

    async def download_media_file(self, client: Client, message) -> Optional[Path]:
        """æ™ºèƒ½é€‰æ‹©ä¸‹è½½æ–¹æ³•ï¼šå°äº50MBçš„éè§†é¢‘æ–‡ä»¶ä½¿ç”¨RAW APIï¼Œå…¶ä»–ä½¿ç”¨stream_media"""
        try:
            # è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
            file_size_mb = self.get_file_size_mb(message)
            is_video = self.is_video_file(message)

            # å†³ç­–é€»è¾‘ï¼šæ–‡ä»¶å¤§å°å°äº50MBä¸”éè§†é¢‘æ–‡ä»¶ä½¿ç”¨RAW APIï¼Œå…¶ä»–ä½¿ç”¨stream_media
            use_raw_api = file_size_mb < 50.0 and not is_video

            if use_raw_api:
                logger.info(f"æ¶ˆæ¯ {message.id}: ä½¿ç”¨RAW APIä¸‹è½½ (å¤§å°: {file_size_mb:.2f} MB, è§†é¢‘: {is_video})")
                return await self.download_media_file_raw_api(client, message)
            else:
                logger.info(f"æ¶ˆæ¯ {message.id}: ä½¿ç”¨Streamä¸‹è½½ (å¤§å°: {file_size_mb:.2f} MB, è§†é¢‘: {is_video})")
                return await self.download_media_file_stream(client, message)

        except Exception as e:
            logger.error(f"ä¸‹è½½æ¶ˆæ¯ {message.id} å¤±è´¥: {e}")
            return None



    async def download_messages_by_ids(self, client: Client, message_ids: List[int], client_index: int,
                                      pre_fetched_messages: Optional[List[Any]] = None) -> Dict:
        """æ ¹æ®æ¶ˆæ¯IDåˆ—è¡¨ä¸‹è½½æ¶ˆæ¯"""
        client_name = f"å®¢æˆ·ç«¯{client_index + 1}"

        if not message_ids:
            logger.warning(f"{client_name} æ²¡æœ‰åˆ†é…åˆ°æ¶ˆæ¯")
            return {
                "client": client_name,
                "downloaded": 0,
                "failed": 0,
                "range": "empty"
            }

        min_id, max_id = min(message_ids), max(message_ids)
        logger.info(f"{client_name} å¼€å§‹ä¸‹è½½ {len(message_ids)} æ¡æ¶ˆæ¯ (IDèŒƒå›´: {min_id}-{max_id})")

        if not self.channel_info:
            self.channel_info = await self.get_channel_info(client)
            logger.info(f"é¢‘é“ä¿¡æ¯: {self.channel_info['username']} - {self.channel_info['title']}")

        downloaded = 0
        failed = 0

        try:
            # å¦‚æœæœ‰é¢„è·å–çš„æ¶ˆæ¯ï¼Œç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™é‡æ–°è·å–
            if pre_fetched_messages:
                logger.info(f"{client_name} ä½¿ç”¨é¢„è·å–çš„ {len(pre_fetched_messages)} æ¡æ¶ˆæ¯")
                all_messages = pre_fetched_messages

                # ç›´æ¥å¤„ç†æ‰€æœ‰æ¶ˆæ¯
                for message in all_messages:
                    if message and hasattr(message, 'media') and message.media:
                        # è·å–æ–‡ä»¶å¤§å°ä¿¡æ¯
                        file_size = self.get_file_size_bytes(message)

                        logger.info(f"{client_name} æ¶ˆæ¯ {message.id} æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")

                        try:
                            is_media_group = self.is_media_group_message(message)
                            if is_media_group:
                                logger.info(f"{client_name} æ£€æµ‹åˆ°åª’ä½“ç»„æ¶ˆæ¯: {message.id} (ç»„ID: {message.media_group_id})")

                            file_path = await self.download_media_file(client, message)

                            if file_path:
                                downloaded += 1
                                if is_media_group:
                                    logger.info(f"{client_name} åª’ä½“ç»„æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {file_path.name}")
                                else:
                                    logger.info(f"{client_name} ä¸‹è½½æˆåŠŸ: {file_path.name}")
                            else:
                                failed += 1

                        except Exception as e:
                            failed += 1
                            logger.error(f"{client_name} ä¸‹è½½æ¶ˆæ¯ {message.id} å¤±è´¥: {e}")
                    else:
                        # å¤„ç†æ–‡æœ¬æ¶ˆæ¯
                        if message:
                            await self.save_text_message(message)
                            downloaded += 1

                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (downloaded + failed) / len(all_messages) * 100
                    if (downloaded + failed) % 10 == 0:  # æ¯10ä¸ªæ¶ˆæ¯æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        logger.info(f"{client_name} è¿›åº¦: {progress:.1f}% ({downloaded} æˆåŠŸ, {failed} å¤±è´¥)")

                    # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                    await asyncio.sleep(0.1)



        except Exception as e:
            logger.error(f"{client_name} ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")

        logger.info(f"{client_name} å®Œæˆä¸‹è½½: {downloaded} æˆåŠŸ, {failed} å¤±è´¥")
        return {
            "client": client_name,
            "downloaded": downloaded,
            "failed": failed,
            "range": f"{min_id}-{max_id}",
            "total_messages": len(message_ids)
        }

    async def run_download(self):
        """è¿è¡Œä¸‹è½½ä»»åŠ¡ - æ™ºèƒ½æ¶ˆæ¯åˆ†é… + å¹¶å‘è·å–"""
        logger.info("ğŸš€ å¼€å§‹å¤šå®¢æˆ·ç«¯æ¶ˆæ¯ä¸‹è½½éªŒè¯ - Stream Media + å¹¶å‘è·å– + æ™ºèƒ½åˆ†é…ç‰ˆæœ¬")
        logger.info(f"ç›®æ ‡é¢‘é“: {TARGET_CHANNEL}")
        logger.info(f"æ¶ˆæ¯èŒƒå›´: {START_MESSAGE_ID} - {END_MESSAGE_ID} (å…± {TOTAL_MESSAGES} æ¡)")
        logger.info(f"å®¢æˆ·ç«¯æ•°é‡: {len(SESSION_NAMES)} ä¸ª")
        logger.info("ğŸ’¡ æ–°ç‰¹æ€§: å¤šå®¢æˆ·ç«¯å¹¶å‘è·å–æ¶ˆæ¯ï¼Œå‡å°‘APIé™æµé£é™©")

        clients = self.create_clients()
        self.stats["start_time"] = time.time()

        try:
            # ä½¿ç”¨æ™ºèƒ½åˆ†é…
            logger.info("ğŸš€ å¯åŠ¨å¹¶å‘è·å– + æ™ºèƒ½åˆ†é…æ¨¡å¼")

            # å…ˆè¿æ¥æ‰€æœ‰å®¢æˆ·ç«¯ç”¨äºæ¶ˆæ¯è·å–ï¼ˆæ·»åŠ è¶…æ—¶å¤„ç†ï¼‰
            connected_clients = []
            for i, client in enumerate(clients):
                try:
                    logger.info(f"ğŸ”„ æ­£åœ¨è¿æ¥å®¢æˆ·ç«¯{i+1}...")
                    # æ·»åŠ è¶…æ—¶å¤„ç†ï¼Œé¿å…æ— é™ç­‰å¾…
                    await asyncio.wait_for(client.start(), timeout=30.0)
                    connected_clients.append(client)
                    logger.info(f"âœ… å®¢æˆ·ç«¯{i+1} è¿æ¥æˆåŠŸ")
                except asyncio.TimeoutError:
                    logger.warning(f"âš ï¸ å®¢æˆ·ç«¯{i+1} è¿æ¥è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                except Exception as e:
                    logger.warning(f"âš ï¸ å®¢æˆ·ç«¯{i+1} è¿æ¥å¤±è´¥: {e}")

            if not connected_clients:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å®¢æˆ·ç«¯")

            # ä½¿ç”¨è¿æ¥çš„å®¢æˆ·ç«¯è¿›è¡Œå¹¶å‘è·å–å’Œæ™ºèƒ½åˆ†é…
            client_message_mapping, client_message_objects, validation_stats = await self.smart_distribute_messages(connected_clients)

            # æ–­å¼€å®¢æˆ·ç«¯è¿æ¥ï¼ˆç¨åä¼šé‡æ–°è¿æ¥ç”¨äºä¸‹è½½ï¼‰
            for client in connected_clients:
                try:
                    await client.stop()
                except:
                    pass

            logger.info("âœ… ä½¿ç”¨å¹¶å‘è·å– + æ™ºèƒ½æ¶ˆæ¯åˆ†é…")

            async def client_task(client, message_ids, pre_fetched_messages, index):
                # é”™å¼€å¯åŠ¨æ—¶é—´ï¼Œé¿å…åŒæ—¶è¿æ¥
                if index > 0:
                    delay_seconds = index * 0.5
                    logger.info(f"å®¢æˆ·ç«¯{index + 1} å°†åœ¨ {delay_seconds} ç§’åå¯åŠ¨...")
                    await asyncio.sleep(delay_seconds)

                logger.info(f"å®¢æˆ·ç«¯{index + 1} æ­£åœ¨å¯åŠ¨...")
                async with client:
                    return await self.download_messages_by_ids(client, message_ids, index, pre_fetched_messages)

            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            tasks = []
            for i, client in enumerate(clients):
                session_name = SESSION_NAMES[i]
                message_ids = client_message_mapping.get(session_name, [])
                pre_fetched_messages = client_message_objects.get(session_name, []) if client_message_objects else []
                task = client_task(client, message_ids, pre_fetched_messages, i)
                tasks.append(task)

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            await self.process_results(results, validation_stats)

        except Exception as e:
            logger.error(f"ä¸‹è½½ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")

    async def process_results(self, results, validation_stats=None):
        """å¤„ç†ä¸‹è½½ç»“æœ"""
        # é˜²æ­¢é‡å¤å¤„ç†
        if self._results_processed:
            logger.warning("âš ï¸ ç»“æœå·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡é‡å¤å¤„ç†")
            return

        self._results_processed = True

        total_downloaded = 0
        total_failed = 0
        client_results = []

        for result in results:
            if isinstance(result, dict):
                total_downloaded += result["downloaded"]
                total_failed += result["failed"]
                client_results.append(result)
            else:
                logger.error(f"ä»»åŠ¡å¼‚å¸¸: {result}")

        # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š Stream Media + å¹¶å‘è·å– + æ™ºèƒ½åˆ†é… ä¸‹è½½ç»“æœç»Ÿè®¡")
        logger.info("="*60)

        # æ˜¾ç¤ºéªŒè¯ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if validation_stats and validation_stats.get("enabled"):
            if validation_stats.get("parallel_fetch"):
                logger.info("ï¿½ å¹¶å‘è·å–ç»Ÿè®¡:")
                logger.info(f"  ä½¿ç”¨å®¢æˆ·ç«¯æ•°: {len(SESSION_NAMES)} ä¸ª")
                logger.info(f"  å¹¶å‘è·å–æ¨¡å¼: âœ… å¯ç”¨")
                logger.info("-" * 60)

            logger.info("ï¿½ğŸ” æ¶ˆæ¯éªŒè¯ç»Ÿè®¡:")
            logger.info(f"  åŸå§‹æ¶ˆæ¯æ•°: {validation_stats['original_count']}")
            logger.info(f"  æœ‰æ•ˆæ¶ˆæ¯æ•°: {validation_stats['valid_count']}")
            logger.info(f"  æ— æ•ˆæ¶ˆæ¯æ•°: {validation_stats['invalid_count']}")
            logger.info(f"  éªŒè¯é€šè¿‡ç‡: {validation_stats['validation_rate']:.1%}")
            logger.info("-" * 60)


        for result in client_results:
            range_info = result.get('range', 'unknown')
            total_msgs = result.get('total_messages', 'unknown')
            logger.info(f"{result['client']}: {result['downloaded']} æˆåŠŸ, {result['failed']} å¤±è´¥ (èŒƒå›´: {range_info}, æ€»æ•°: {total_msgs})")

        elapsed_time = time.time() - self.stats["start_time"]

        # è®¡ç®—æˆåŠŸç‡ï¼ˆåŸºäºå®é™…åˆ†é…çš„æ¶ˆæ¯æ•°ï¼‰
        actual_total = validation_stats.get('valid_count', TOTAL_MESSAGES) if validation_stats and validation_stats.get('enabled') else TOTAL_MESSAGES
        success_rate = (total_downloaded / actual_total * 100) if actual_total > 0 else 0

        logger.info("-" * 60)
        logger.info(f"æ€»è®¡: {total_downloaded} æˆåŠŸ, {total_failed} å¤±è´¥")
        logger.info(f"æˆåŠŸç‡: {success_rate:.1f}% (åŸºäºæœ‰æ•ˆæ¶ˆæ¯)")
        logger.info(f"è€—æ—¶: {elapsed_time:.1f} ç§’")

        if elapsed_time > 0:
            logger.info(f"å¹³å‡é€Ÿåº¦: {total_downloaded / elapsed_time:.1f} æ¡/ç§’")

        logger.info(f"ä¸‹è½½ç›®å½•: {self.download_dir.absolute()}")
        logger.info("="*60)


async def main():
    """ä¸»å‡½æ•°"""
    # å¯åŠ¨å¸¦å®½ç›‘æ§
    threading.Thread(target=monitor_bandwidth, daemon=True).start()

    try:
        downloader = MultiClientDownloader()
        await downloader.run_download()
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    # æ˜¾ç¤ºæ—¥å¿—æ–‡ä»¶ä½ç½®
    logs_dir = Path("logs")
    log_file = logs_dir / "test_downloader_stream.log"
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶ä½ç½®: {log_file.absolute()}")
    logger.info("ğŸ—‘ï¸ æ—¥å¿—æ–‡ä»¶å·²æ¸…é™¤ï¼Œå¼€å§‹æ–°çš„æ—¥å¿—è®°å½•")

    # æ£€æŸ¥ TgCrypto - ç®€åŒ–ç‰ˆæœ¬
    try:
        import tgcrypto
        logger.info("âœ… TgCrypto å·²å¯ç”¨")
    except ImportError:
        logger.warning("âš ï¸ TgCrypto æœªå®‰è£…ï¼Œå»ºè®®å®‰è£…: pip install tgcrypto")

    # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    logger.info("ğŸŒŠ ä½¿ç”¨ Pyrogram stream_media æ–¹æ³•è¿›è¡Œæµå¼ä¸‹è½½")
    logger.info("ğŸš€ ç‰¹æ€§: å¤šå®¢æˆ·ç«¯å¹¶å‘è·å–æ¶ˆæ¯ï¼Œå‡å°‘APIé™æµ")
    logger.info("ğŸ§  æ ¸å¿ƒ: æ™ºèƒ½åª’ä½“ç»„æ„ŸçŸ¥åˆ†é…ç®—æ³•")
    logger.info("âš¡ æ™ºèƒ½: åŸºäºæ–‡ä»¶å¤§å°å’Œç±»å‹çš„ä¸‹è½½æ–¹æ³•é€‰æ‹©")
    logger.info("ğŸ’¡ ä¼˜åŠ¿: å†…å­˜æ•ˆç‡é«˜ã€è‡ªåŠ¨æ•°æ®ä¸­å¿ƒé€‰æ‹©ã€å†…ç½®é”™è¯¯å¤„ç†ã€å¹¶å‘åŠ é€Ÿ")

    asyncio.run(main())
