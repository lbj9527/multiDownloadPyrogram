"""
ä¸‹è½½æ¥å£
ä¸ºUIã€APIç­‰æä¾›ç»Ÿä¸€çš„ä¸‹è½½æ¥å£
"""

import asyncio
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime

from models import DownloadTask, TaskRange, TaskStatus
from services import ClientManager
from core import TelegramDownloader
from core.message_grouper import MessageGrouper
# å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯å¯¼å…¥
# from core.task_distribution import TaskDistributor, DistributionConfig, DistributionMode
# from core.task_distribution.base import LoadBalanceMetric
from utils import get_logger

logger = get_logger(__name__)


class DownloadInterface:
    """ä¸‹è½½æ¥å£ç±»"""
    
    def __init__(self, client_manager: ClientManager, downloader: TelegramDownloader):
        self.client_manager = client_manager
        self.downloader = downloader
        self.active_tasks: Dict[str, DownloadTask] = {}
        self.progress_callbacks: List[Callable] = []
    
    def add_progress_callback(self, callback: Callable[[Dict[str, Any]], None]):
        """
        æ·»åŠ è¿›åº¦å›è°ƒå‡½æ•°
        
        Args:
            callback: è¿›åº¦å›è°ƒå‡½æ•°
        """
        self.progress_callbacks.append(callback)
    
    def remove_progress_callback(self, callback: Callable):
        """
        ç§»é™¤è¿›åº¦å›è°ƒå‡½æ•°
        
        Args:
            callback: è¦ç§»é™¤çš„å›è°ƒå‡½æ•°
        """
        if callback in self.progress_callbacks:
            self.progress_callbacks.remove(callback)
    
    def _notify_progress(self, progress_data: Dict[str, Any]):
        """
        é€šçŸ¥è¿›åº¦æ›´æ–°
        
        Args:
            progress_data: è¿›åº¦æ•°æ®
        """
        for callback in self.progress_callbacks:
            try:
                callback(progress_data)
            except Exception as e:
                logger.error(f"è¿›åº¦å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
    
    async def download_messages(
        self,
        channel: str,
        start_message_id: int,
        end_message_id: int,
        batch_size: int = 200,
        storage_mode: str = "hybrid"
    ) -> List[Dict[str, Any]]:
        """
        ä¸‹è½½æ¶ˆæ¯èŒƒå›´
        
        Args:
            channel: é¢‘é“åç§°
            start_message_id: å¼€å§‹æ¶ˆæ¯ID
            end_message_id: ç»“æŸæ¶ˆæ¯ID
            batch_size: æ‰¹æ¬¡å¤§å°
            storage_mode: å­˜å‚¨æ¨¡å¼
            
        Returns:
            ä¸‹è½½ç»“æœåˆ—è¡¨
        """
        logger.info(f"å¼€å§‹ä¸‹è½½ä»»åŠ¡: {channel} ({start_message_id}-{end_message_id})")
        
        # è·å–å¯ç”¨å®¢æˆ·ç«¯
        available_clients = self.client_manager.get_available_clients()
        if not available_clients:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å®¢æˆ·ç«¯")
        
        # åˆ›å»ºä»»åŠ¡èŒƒå›´
        task_ranges = self.downloader.create_task_ranges(
            start_message_id, end_message_id, len(available_clients)
        )
        
        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        tasks = []
        for i, (client_name, task_range) in enumerate(zip(available_clients, task_ranges)):
            task = DownloadTask(
                client_name=client_name,
                channel=channel,
                message_range=task_range,
                batch_size=batch_size,
                storage_mode=storage_mode
            )
            
            # å¯åŠ¨ä»»åŠ¡
            task.start(client_name)
            
            # å­˜å‚¨æ´»åŠ¨ä»»åŠ¡
            self.active_tasks[task.task_id] = task
            
            # æ›´æ–°å®¢æˆ·ç«¯ä»»åŠ¡ä¿¡æ¯
            self.client_manager.update_client_task(client_name, task.task_id)
            
            tasks.append(task)
            
            logger.info(f"åˆ›å»ºä»»åŠ¡ {i+1}: {client_name} -> {task_range}")
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        download_tasks = []
        for task in tasks:
            client = self.client_manager.get_client(task.client_name)
            if client:
                download_task = self._execute_task_with_progress(client, task)
                download_tasks.append(download_task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*download_tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        processed_results = []
        for task, result in zip(tasks, results):
            if isinstance(result, Exception):
                logger.error(f"ä»»åŠ¡ {task.task_id} æ‰§è¡Œå¤±è´¥: {result}")
                task.fail(str(result))
                processed_results.append({
                    "task_id": task.task_id,
                    "client": task.client_name,
                    "status": "failed",
                    "error": str(result),
                    "downloaded": 0,
                    "failed": task.message_range.total_messages if task.message_range else 0
                })
            else:
                task.complete(result)
                processed_results.append({
                    "task_id": task.task_id,
                    "client": task.client_name,
                    "status": "completed",
                    "downloaded": result.downloaded,
                    "failed": result.failed,
                    "duration": result.duration
                })
            
            # æ¸…ç†ä»»åŠ¡ä¿¡æ¯
            self.client_manager.update_client_task(task.client_name, None)
            if task.task_id in self.active_tasks:
                del self.active_tasks[task.task_id]
        
        logger.info("æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆ")
        return processed_results
    
    async def _execute_task_with_progress(self, client, task: DownloadTask):
        """
        æ‰§è¡Œä»»åŠ¡å¹¶æŠ¥å‘Šè¿›åº¦
        
        Args:
            client: Pyrogramå®¢æˆ·ç«¯
            task: ä¸‹è½½ä»»åŠ¡
            
        Returns:
            ä»»åŠ¡ç»“æœ
        """
        try:
            # åˆ›å»ºè¿›åº¦ç›‘æ§ä»»åŠ¡
            progress_task = asyncio.create_task(
                self._monitor_task_progress(task)
            )
            
            # æ‰§è¡Œä¸‹è½½ä»»åŠ¡
            result = await self.downloader.download_range(client, task)
            
            # å–æ¶ˆè¿›åº¦ç›‘æ§
            progress_task.cancel()
            
            return result
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _monitor_task_progress(self, task: DownloadTask):
        """
        ç›‘æ§ä»»åŠ¡è¿›åº¦
        
        Args:
            task: ä¸‹è½½ä»»åŠ¡
        """
        try:
            while not task.is_completed:
                # å‘é€è¿›åº¦æ›´æ–°
                progress_data = {
                    "task_id": task.task_id,
                    "client": task.client_name,
                    "status": task.status.value,
                    "progress_percentage": task.progress_percentage,
                    "processed_messages": task.processed_messages,
                    "total_messages": task.total_messages,
                    "downloaded_files": task.downloaded_files,
                    "failed_downloads": task.failed_downloads,
                    "duration": task.duration,
                    "timestamp": datetime.now().isoformat()
                }
                
                self._notify_progress(progress_data)
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ¬¡æ£€æŸ¥
                await asyncio.sleep(1.0)
                
        except asyncio.CancelledError:
            # ä»»åŠ¡è¢«å–æ¶ˆï¼Œæ­£å¸¸é€€å‡º
            pass
        except Exception as e:
            logger.error(f"ç›‘æ§ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")
    
    def get_active_tasks(self) -> List[Dict[str, Any]]:
        """
        è·å–æ´»åŠ¨ä»»åŠ¡åˆ—è¡¨
        
        Returns:
            æ´»åŠ¨ä»»åŠ¡ä¿¡æ¯åˆ—è¡¨
        """
        return [task.to_dict() for task in self.active_tasks.values()]
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–ä»»åŠ¡çŠ¶æ€
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
        """
        task = self.active_tasks.get(task_id)
        return task.to_dict() if task else None
    
    async def cancel_task(self, task_id: str) -> bool:
        """
        å–æ¶ˆä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦å–æ¶ˆæˆåŠŸ
        """
        task = self.active_tasks.get(task_id)
        if not task:
            return False
        
        try:
            # æ ‡è®°ä»»åŠ¡ä¸ºå–æ¶ˆçŠ¶æ€
            task.cancel()
            
            # æ›´æ–°å®¢æˆ·ç«¯çŠ¶æ€
            self.client_manager.update_client_task(task.client_name, None)
            
            # ä»æ´»åŠ¨ä»»åŠ¡ä¸­ç§»é™¤
            del self.active_tasks[task_id]
            
            logger.info(f"ä»»åŠ¡ {task_id} å·²å–æ¶ˆ")
            return True
            
        except Exception as e:
            logger.error(f"å–æ¶ˆä»»åŠ¡ {task_id} å¤±è´¥: {e}")
            return False
    
    async def cancel_all_tasks(self) -> int:
        """
        å–æ¶ˆæ‰€æœ‰æ´»åŠ¨ä»»åŠ¡
        
        Returns:
            å–æ¶ˆçš„ä»»åŠ¡æ•°é‡
        """
        cancelled_count = 0
        task_ids = list(self.active_tasks.keys())
        
        for task_id in task_ids:
            if await self.cancel_task(task_id):
                cancelled_count += 1
        
        logger.info(f"å·²å–æ¶ˆ {cancelled_count} ä¸ªä»»åŠ¡")
        return cancelled_count
    
    def get_download_statistics(self) -> Dict[str, Any]:
        """
        è·å–ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        # è·å–å®¢æˆ·ç«¯ç»Ÿè®¡
        client_stats = self.client_manager.get_client_stats()
        
        # è·å–ä¸‹è½½å™¨ç»Ÿè®¡
        download_stats = self.downloader.get_download_stats()
        
        # è·å–æ´»åŠ¨ä»»åŠ¡ç»Ÿè®¡
        active_tasks_count = len(self.active_tasks)
        running_tasks = sum(1 for task in self.active_tasks.values() if task.is_running)
        
        return {
            "client_stats": client_stats,
            "download_stats": download_stats,
            "active_tasks": active_tasks_count,
            "running_tasks": running_tasks,
            "task_details": self.get_active_tasks()
        }

    async def download_messages_with_media_group_awareness(
        self,
        channel: str,
        start_message_id: int,
        end_message_id: int,
        batch_size: int = 200,
        distribution_mode = None,
        task_distribution_config = None
    ) -> List[Dict[str, Any]]:
        """
        åª’ä½“ç»„æ„ŸçŸ¥çš„æ¶ˆæ¯ä¸‹è½½

        Args:
            channel: é¢‘é“åç§°
            start_message_id: å¼€å§‹æ¶ˆæ¯ID
            end_message_id: ç»“æŸæ¶ˆæ¯ID
            batch_size: æ‰¹æ¬¡å¤§å°
            distribution_mode: åˆ†é…æ¨¡å¼ï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¸‹è½½ç»“æœåˆ—è¡¨
        """
        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯å¯¼å…¥
        from core.task_distribution import TaskDistributor, DistributionConfig, DistributionMode
        from core.task_distribution.base import LoadBalanceMetric

        logger.info(f"å¼€å§‹åª’ä½“ç»„æ„ŸçŸ¥ä¸‹è½½: {channel} ({start_message_id}-{end_message_id})")

        # è·å–å¯ç”¨å®¢æˆ·ç«¯
        available_clients = self.client_manager.get_available_clients()
        if not available_clients:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å®¢æˆ·ç«¯")

        try:
            # 1. å¹¶å‘è·å–æ¶ˆæ¯å¯¹è±¡é˜¶æ®µ
            logger.info("ğŸ“¦ å¹¶å‘è·å–æ¶ˆæ¯å¯¹è±¡...")
            all_messages = await self._fetch_messages_concurrently(
                available_clients, channel, start_message_id, end_message_id, batch_size
            )

            # 2. æ¶ˆæ¯åˆ†ç»„é˜¶æ®µ
            logger.info("ğŸ§  åˆ†æåª’ä½“ç»„...")
            # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤å€¼
            max_retries = 3
            if task_distribution_config and hasattr(task_distribution_config, 'max_retries'):
                max_retries = task_distribution_config.max_retries

            message_grouper = MessageGrouper(
                batch_size=batch_size,
                max_retries=max_retries
            )

            # ä»å·²è·å–çš„æ¶ˆæ¯åˆ—è¡¨è¿›è¡Œåˆ†ç»„
            message_collection = message_grouper.group_messages_from_list(all_messages)

            # è®°å½•åˆ†ç»„ç»Ÿè®¡
            grouping_stats = message_collection.get_statistics()

            # 2. ä»»åŠ¡åˆ†é…é˜¶æ®µ

            # åˆ›å»ºåˆ†é…é…ç½®
            if task_distribution_config:
                # è½¬æ¢é…ç½®ç±»å‹
                distribution_config = DistributionConfig(
                    mode=DistributionMode(task_distribution_config.mode.value),
                    load_balance_metric=LoadBalanceMetric(task_distribution_config.load_balance_metric.value),
                    max_imbalance_ratio=task_distribution_config.max_imbalance_ratio,
                    prefer_large_groups_first=task_distribution_config.prefer_large_groups_first,
                    enable_validation=task_distribution_config.enable_validation
                )

                # æ·»åŠ æ¶ˆæ¯IDéªŒè¯é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if hasattr(task_distribution_config, 'enable_message_id_validation'):
                    distribution_config.enable_message_id_validation = task_distribution_config.enable_message_id_validation
                if distribution_mode:
                    distribution_config.mode = distribution_mode
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                distribution_config = DistributionConfig(
                    mode=distribution_mode or DistributionMode.MEDIA_GROUP_AWARE,
                    load_balance_metric=LoadBalanceMetric.FILE_COUNT,
                    max_imbalance_ratio=0.3,
                    prefer_large_groups_first=True,
                    enable_validation=True
                )
                # é»˜è®¤å¯ç”¨æ¶ˆæ¯IDéªŒè¯
                distribution_config.enable_message_id_validation = True

            # æ‰§è¡Œä»»åŠ¡åˆ†é…
            task_distributor = TaskDistributor(distribution_config)
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨å®¢æˆ·ç«¯è¿›è¡Œä»»åŠ¡åˆ†é…
            first_client = self.client_manager.get_client(available_clients[0])
            distribution_result = await task_distributor.distribute_tasks(
                message_collection, available_clients, client=first_client, channel=channel
            )

            # æ‰“å°ä»»åŠ¡åˆ†é…è¯¦æƒ…
            self._log_task_distribution_details(distribution_result)

            # 3. æ‰§è¡Œä¸‹è½½ä»»åŠ¡
            logger.info("ğŸš€ å¼€å§‹å¹¶å‘ä¸‹è½½...")
            download_tasks = []

            for assignment in distribution_result.client_assignments:
                if assignment.total_messages > 0:
                    # è·å–è¯¥å®¢æˆ·ç«¯çš„æ‰€æœ‰æ¶ˆæ¯
                    client_messages = assignment.get_all_messages()

                    # åˆ›å»ºä¸‹è½½ä»»åŠ¡
                    task = self._create_media_group_aware_task(
                        assignment.client_name,
                        channel,
                        client_messages,
                        batch_size
                    )
                    download_tasks.append(task)

            # å¹¶å‘æ‰§è¡Œä¸‹è½½ä»»åŠ¡
            results = await self._execute_media_group_aware_tasks(download_tasks)

            # 4. è®°å½•æœ€ç»ˆç»Ÿè®¡
            self._log_media_group_aware_results(results, distribution_result)

            return results

        except Exception as e:
            logger.error(f"åª’ä½“ç»„æ„ŸçŸ¥ä¸‹è½½å¤±è´¥: {e}")
            raise

    async def _fetch_messages_concurrently(
        self,
        available_clients: List[str],
        channel: str,
        start_message_id: int,
        end_message_id: int,
        batch_size: int
    ) -> List[Any]:
        """
        å¹¶å‘è·å–æ¶ˆæ¯å¯¹è±¡

        Args:
            available_clients: å¯ç”¨å®¢æˆ·ç«¯åˆ—è¡¨
            channel: é¢‘é“åç§°
            start_message_id: å¼€å§‹æ¶ˆæ¯ID
            end_message_id: ç»“æŸæ¶ˆæ¯ID
            batch_size: æ‰¹æ¬¡å¤§å°

        Returns:
            åˆå¹¶åçš„æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨
        """
        client_count = len(available_clients)
        logger.info(f"ä½¿ç”¨ {client_count} ä¸ªå®¢æˆ·ç«¯å¹¶å‘è·å–æ¶ˆæ¯")

        # åˆ†å‰²æ¶ˆæ¯èŒƒå›´
        message_ranges = self._split_message_range(start_message_id, end_message_id, client_count)

        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        fetch_tasks = []
        for i, (range_start, range_end) in enumerate(message_ranges):
            client_name = available_clients[i]
            client = self.client_manager.get_client(client_name)

            logger.info(f"å®¢æˆ·ç«¯ {client_name} è´Ÿè´£æ¶ˆæ¯èŒƒå›´: {range_start}-{range_end}")

            # åˆ›å»ºæ¶ˆæ¯è·å–ä»»åŠ¡
            task = self._fetch_message_range_for_client(
                client, channel, range_start, range_end, batch_size, client_name
            )
            fetch_tasks.append(task)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è·å–ä»»åŠ¡
        logger.info("ğŸš€ å¼€å§‹å¹¶å‘è·å–æ¶ˆæ¯...")
        message_batches = await asyncio.gather(*fetch_tasks, return_exceptions=True)

        # å¤„ç†è·å–ç»“æœ
        all_messages = []
        for i, batch_result in enumerate(message_batches):
            client_name = available_clients[i]

            if isinstance(batch_result, Exception):
                logger.error(f"å®¢æˆ·ç«¯ {client_name} è·å–æ¶ˆæ¯å¤±è´¥: {batch_result}")
                # å¯ä»¥åœ¨è¿™é‡Œå®ç°é‡è¯•é€»è¾‘ï¼Œæš‚æ—¶è·³è¿‡
                continue

            if batch_result:
                all_messages.extend(batch_result)
                logger.info(f"å®¢æˆ·ç«¯ {client_name} æˆåŠŸè·å– {len(batch_result)} æ¡æ¶ˆæ¯")

        # åˆå¹¶å¹¶æ’åºæ¶ˆæ¯
        sorted_messages = self._merge_and_sort_messages(all_messages)
        logger.info(f"âœ… å¹¶å‘è·å–å®Œæˆï¼Œæ€»è®¡ {len(sorted_messages)} æ¡æ¶ˆæ¯")

        return sorted_messages

    def _split_message_range(
        self,
        start_id: int,
        end_id: int,
        client_count: int
    ) -> List[tuple]:
        """
        å°†æ¶ˆæ¯èŒƒå›´å¹³å‡åˆ†å‰²ç»™å¤šä¸ªå®¢æˆ·ç«¯

        Args:
            start_id: å¼€å§‹æ¶ˆæ¯ID
            end_id: ç»“æŸæ¶ˆæ¯ID
            client_count: å®¢æˆ·ç«¯æ•°é‡

        Returns:
            æ¶ˆæ¯èŒƒå›´åˆ—è¡¨ [(start1, end1), (start2, end2), ...]
        """
        total_messages = end_id - start_id + 1
        messages_per_client = total_messages // client_count
        remainder = total_messages % client_count

        ranges = []
        current_start = start_id

        for i in range(client_count):
            # å‰remainderä¸ªå®¢æˆ·ç«¯å¤šåˆ†é…1æ¡æ¶ˆæ¯
            current_count = messages_per_client + (1 if i < remainder else 0)
            current_end = current_start + current_count - 1

            ranges.append((current_start, current_end))
            current_start = current_end + 1

        return ranges

    def _merge_and_sort_messages(self, messages: List[Any]) -> List[Any]:
        """
        åˆå¹¶æ¶ˆæ¯åˆ—è¡¨å¹¶æŒ‰æ¶ˆæ¯IDæ’åº

        Args:
            messages: æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨

        Returns:
            æ’åºåçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # è¿‡æ»¤Noneæ¶ˆæ¯å¹¶æŒ‰IDæ’åº
        valid_messages = [msg for msg in messages if msg is not None]
        sorted_messages = sorted(valid_messages, key=lambda msg: msg.id if msg else 0)

        return sorted_messages

    async def _fetch_message_range_for_client(
        self,
        client,
        channel: str,
        start_id: int,
        end_id: int,
        batch_size: int,
        client_name: str
    ) -> List[Any]:
        """
        å•ä¸ªå®¢æˆ·ç«¯è·å–æŒ‡å®šèŒƒå›´çš„æ¶ˆæ¯

        Args:
            client: Pyrogramå®¢æˆ·ç«¯
            channel: é¢‘é“åç§°
            start_id: å¼€å§‹æ¶ˆæ¯ID
            end_id: ç»“æŸæ¶ˆæ¯ID
            batch_size: æ‰¹æ¬¡å¤§å°
            client_name: å®¢æˆ·ç«¯åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨
        """
        from core.message_grouper import MessageGrouper
        from pyrogram.errors import FloodWait
        import asyncio

        # ç”Ÿæˆæ¶ˆæ¯IDåˆ—è¡¨
        message_ids = list(range(start_id, end_id + 1))
        all_messages = []

        # æŒ‰æ‰¹æ¬¡è·å–æ¶ˆæ¯
        for i in range(0, len(message_ids), batch_size):
            batch_ids = message_ids[i:i + batch_size]

            try:
                # è·å–æ¶ˆæ¯æ‰¹æ¬¡
                messages = await client.get_messages(channel, batch_ids)

                # ç¡®ä¿è¿”å›åˆ—è¡¨æ ¼å¼
                if not isinstance(messages, list):
                    messages = [messages] if messages else []

                all_messages.extend(messages)

                # æ˜¾ç¤ºè¿›åº¦
                progress = (i + len(batch_ids)) / len(message_ids) * 100
                logger.debug(f"{client_name} è·å–è¿›åº¦: {progress:.1f}%")

            except FloodWait as e:
                logger.warning(f"{client_name} é‡åˆ°é™æµï¼Œç­‰å¾… {e.value} ç§’")
                await asyncio.sleep(e.value)
                # é‡è¯•å½“å‰æ‰¹æ¬¡
                try:
                    messages = await client.get_messages(channel, batch_ids)
                    if not isinstance(messages, list):
                        messages = [messages] if messages else []
                    all_messages.extend(messages)
                except Exception as retry_e:
                    logger.error(f"{client_name} é‡è¯•è·å–æ¶ˆæ¯å¤±è´¥: {retry_e}")
                    # æ·»åŠ å¯¹åº”æ•°é‡çš„Noneä»¥ä¿æŒç´¢å¼•
                    all_messages.extend([None] * len(batch_ids))

            except Exception as e:
                logger.error(f"{client_name} è·å–æ¶ˆæ¯æ‰¹æ¬¡å¤±è´¥: {e}")
                # æ·»åŠ å¯¹åº”æ•°é‡çš„Noneä»¥ä¿æŒç´¢å¼•
                all_messages.extend([None] * len(batch_ids))

            # æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if i + batch_size < len(message_ids):
                from config import app_settings
                await asyncio.sleep(app_settings.download.batch_delay)

        # è¿‡æ»¤æœ‰æ•ˆæ¶ˆæ¯
        valid_messages = [msg for msg in all_messages if msg is not None]
        logger.info(f"{client_name} å®Œæˆè·å–: {len(valid_messages)} æ¡æœ‰æ•ˆæ¶ˆæ¯")

        return valid_messages

    def _create_media_group_aware_task(
        self,
        client_name: str,
        channel: str,
        messages: List[Any],
        batch_size: int
    ) -> Dict[str, Any]:
        """åˆ›å»ºåª’ä½“ç»„æ„ŸçŸ¥çš„ä¸‹è½½ä»»åŠ¡"""
        return {
            "client_name": client_name,
            "channel": channel,
            "messages": messages,
            "batch_size": batch_size,
            "task_type": "media_group_aware"
        }

    async def _execute_media_group_aware_tasks(
        self,
        tasks: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """æ‰§è¡Œåª’ä½“ç»„æ„ŸçŸ¥çš„ä¸‹è½½ä»»åŠ¡"""
        async def execute_single_task(task_info: Dict[str, Any]) -> Dict[str, Any]:
            client_name = task_info["client_name"]
            channel = task_info["channel"]
            messages = task_info["messages"]

            try:
                client = self.client_manager.get_client(client_name)

                # ä½¿ç”¨ä¸‹è½½å™¨å¤„ç†æ¶ˆæ¯åˆ—è¡¨
                result = await self.downloader.download_message_list(
                    client, channel, messages
                )

                return {
                    "client": client_name,
                    "status": "completed",
                    "downloaded": result.get("downloaded", 0),
                    "failed": result.get("failed", 0),
                    "total_messages": len(messages)
                }

            except Exception as e:
                logger.error(f"å®¢æˆ·ç«¯ {client_name} ä¸‹è½½å¤±è´¥: {e}")
                return {
                    "client": client_name,
                    "status": "failed",
                    "error": str(e),
                    "downloaded": 0,
                    "failed": len(messages),
                    "total_messages": len(messages)
                }

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        return await asyncio.gather(*[
            execute_single_task(task) for task in tasks
        ])

    def _log_media_group_aware_results(
        self,
        results: List[Dict[str, Any]],
        distribution_result
    ):
        """è®°å½•åª’ä½“ç»„æ„ŸçŸ¥ä¸‹è½½çš„ç»“æœ"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š åª’ä½“ç»„æ„ŸçŸ¥ä¸‹è½½ç»“æœ")
        logger.info("=" * 60)

        total_downloaded = sum(r.get("downloaded", 0) for r in results)
        total_failed = sum(r.get("failed", 0) for r in results)
        total_messages = sum(r.get("total_messages", 0) for r in results)

        logger.info(f"æ€»è®¡: {total_downloaded} æˆåŠŸ, {total_failed} å¤±è´¥")
        logger.info(f"æˆåŠŸç‡: {(total_downloaded / total_messages * 100) if total_messages > 0 else 0:.1f}%")

        # æ˜¾ç¤ºåˆ†é…ç»Ÿè®¡
        balance_stats = distribution_result.get_load_balance_stats()
        logger.info(f"è´Ÿè½½å‡è¡¡æ¯”ä¾‹: {balance_stats.get('file_balance_ratio', 0):.3f}")

        logger.info("=" * 60)

    def _log_task_distribution_details(self, distribution_result):
        """è®°å½•ä»»åŠ¡åˆ†é…è¯¦æƒ…"""
        logger.info("\n" + "ğŸ¯" * 20 + " ä»»åŠ¡åˆ†é…è¯¦æƒ… " + "ğŸ¯" * 20)
        logger.info(f"åˆ†é…ç­–ç•¥: {distribution_result.distribution_strategy}")
        logger.info(f"å®¢æˆ·ç«¯æ•°é‡: {len(distribution_result.client_assignments)}")
        logger.info(f"æ€»æ¶ˆæ¯æ•°: {distribution_result.total_messages}")
        logger.info(f"æ€»æ–‡ä»¶æ•°: {distribution_result.total_files}")

        logger.info("\nğŸ“Š å„å®¢æˆ·ç«¯åˆ†é…æ¦‚è§ˆ:")
        for assignment in distribution_result.client_assignments:
            # è·å–æ‰€æœ‰æ¶ˆæ¯ID
            all_message_ids = []
            for group in assignment.message_groups:
                all_message_ids.extend(group.message_ids)

            if all_message_ids:
                all_message_ids.sort()
                # å®Œæ•´æ˜¾ç¤ºæ‰€æœ‰æ¶ˆæ¯IDï¼Œè€Œä¸æ˜¯èŒƒå›´
                id_list = str(all_message_ids)
            else:
                id_list = "æ— æ¶ˆæ¯"

            # ç»Ÿè®¡åª’ä½“ç»„å’Œå•æ¶ˆæ¯
            media_groups = [g for g in assignment.message_groups if g.is_media_group]
            single_messages = [g for g in assignment.message_groups if not g.is_media_group]

            logger.info(f"  {assignment.client_name}:")
            logger.info(f"    ğŸ“ æ¶ˆæ¯æ•°é‡: {assignment.total_messages}")
            logger.info(f"    ğŸ“ æ–‡ä»¶æ•°é‡: {assignment.total_files}")
            logger.info(f"    ğŸ”¢ å®Œæ•´æ¶ˆæ¯IDåˆ—è¡¨: {id_list}")
            logger.info(f"    ğŸ“¦ åª’ä½“ç»„: {len(media_groups)} ä¸ª")
            logger.info(f"    ğŸ“„ å•æ¡æ¶ˆæ¯: {len(single_messages)} ä¸ª")

            # æ˜¾ç¤ºä¼°ç®—å¤§å°
            size_mb = assignment.estimated_size / (1024 * 1024)
            logger.info(f"    ğŸ’¾ ä¼°ç®—å¤§å°: {size_mb:.1f} MB")

        # æ˜¾ç¤ºè´Ÿè½½å‡è¡¡ç»Ÿè®¡
        balance_stats = distribution_result.get_load_balance_stats()
        if balance_stats:
            logger.info(f"\nâš–ï¸ è´Ÿè½½å‡è¡¡ç»Ÿè®¡:")
            logger.info(f"  æ–‡ä»¶åˆ†å¸ƒ: {balance_stats.get('file_distribution', [])}")
            logger.info(f"  å‡è¡¡æ¯”ä¾‹: {balance_stats.get('file_balance_ratio', 0):.3f}")
            logger.info(f"  å¹³å‡æ–‡ä»¶æ•°/å®¢æˆ·ç«¯: {balance_stats.get('average_files_per_client', 0):.1f}")

        logger.info("ğŸ¯" * 60)
